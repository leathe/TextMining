{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 25,
=======
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_features(reviews):\n",
    "    all_words = []\n",
    "    for (words, sentiment) in reviews:\n",
    "          all_words.extend(words)\n",
    "    wordlist = nltk.FreqDist(all_words)\n",
    "    word_features = []\n",
    "    for feature in wordlist:\n",
    "        if wordlist[feature] > 10000:\n",
    "            word_features.append(feature)\n",
    "    print(len(word_features))\n",
    "    return word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "            for category in movie_reviews.categories()\n",
    "            for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "word_features = list(all_words)[:50]\n",
    "\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 89,
=======
   "execution_count": 130,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "0.608\n"
=======
      "Reviews filtered\n",
      "64\n",
      "Word Features Generated\n",
      "Training and Test Sets Created\n",
      "Generating NaiveBayes Classifier Model\n",
      "NaiveBayes Classifier Model generated\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
<<<<<<< Updated upstream
    "print(nltk.classify.accuracy(classifier, test_set))"
=======
    "print(\"Reviews filtered\")\n",
    "\n",
    "word_features = get_word_features(train_reviews+test_reviews)\n",
    "print(\"Word Features Generated\")\n",
    "\n",
    "training_set = nltk.classify.apply_features(extract_features, train_reviews)\n",
    "test_set = nltk.classify.apply_features(extract_features, test_reviews)\n",
    "print(\"Training and Test Sets Created\")\n",
    "\n",
    "# NaiveBayes Classifier\n",
    "print(\"Generating NaiveBayes Classifier Model\")\n",
    "NB_classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "sorted(NB_classifier.labels())\n",
    "print(\"NaiveBayes Classifier Model generated\")\n",
    "\n",
    "#Decision Tree Classifier\n",
    "# print(\"Generating Decision Tree Classifier Model\")\n",
    "# print('This is going to take a while...')\n",
    "# DT_classifier = nltk.classify.DecisionTreeClassifier.train(training_set, entropy_cutoff=0, support_cutoff=0)\n",
    "# print('Sorting DT Classifier labels...')\n",
    "# sorted(DT_classifier.labels())\n",
    "# print(\"Decision Tree Classifier Model generated\")"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 91,
=======
   "execution_count": 131,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "Most Informative Features\n",
      "     contains(continues) = True              pos : neg    =      2.0 : 1.0\n",
      "         contains(sorta) = True              pos : neg    =      1.9 : 1.0\n",
      "      contains(accident) = True              pos : neg    =      1.8 : 1.0\n",
      "           contains(his) = False             neg : pos    =      1.6 : 1.0\n",
      "            contains(to) = False             neg : pos    =      1.6 : 1.0\n"
=======
      "Naive Bayes Classifier:\n",
      "0.61892\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-e5efbdabfab7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Naive Bayes Classifier:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNB_classifier\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mpdist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mNB_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprob_classify_many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%.4f %.4f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Applications\\Anaconda3\\lib\\site-packages\\nltk\\classify\\api.py\u001b[0m in \u001b[0;36mprob_classify_many\u001b[1;34m(self, featuresets)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mProbDistI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \"\"\"\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprob_classify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeaturesets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Applications\\Anaconda3\\lib\\site-packages\\nltk\\classify\\api.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mProbDistI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \"\"\"\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprob_classify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeaturesets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Applications\\Anaconda3\\lib\\site-packages\\nltk\\classify\\naivebayes.py\u001b[0m in \u001b[0;36mprob_classify\u001b[1;34m(self, featureset)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;31m# Otherwise, we'll just assign a probability of 0 to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;31m# everything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mfeatureset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_labels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
<<<<<<< Updated upstream
    "classifier.show_most_informative_features(5)"
=======
    "#Print NB Classifier\n",
    "print('Naive Bayes Classifier:')\n",
    "print(nltk.classify.accuracy(NB_classifier,test_set))\n",
    "for pdist in NB_classifier.prob_classify_many(test_set):\n",
    "    print('%.4f %.4f' % (pdist.prob('x'), pdist.prob('y')))\n",
    "\n",
    "#Print DT Classifier\n",
    "#print(DT_classifier)\n",
    "#DT_classifier.classify_many(test_set)\n"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
<<<<<<< Updated upstream
=======
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
>>>>>>> Stashed changes
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
